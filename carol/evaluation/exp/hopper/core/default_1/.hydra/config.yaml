use_safety_loss: true
use_concrete_safety_loss: false
no_policy_loss: false
regulate_delta: false
safety_method: symbolic
domain: box
seed: 1
device: cuda:0
log_frequency_agent: 1000
save_video: false
debug_mode: true
no_safety_test: false
resume: false
experiment: default
root_dir: ./exp
algorithm:
  name: core
  normalize: true
  normalize_double_precision: true
  target_is_delta: true
  learned_rewards: true
  freq_train_model: ${overrides.freq_train_model}
  real_data_ratio: 0.0
  dataset_size: None
  sac_samples_action: true
  initial_exploration_steps: 5000
  random_initial_explore: false
  num_eval_episodes: 20
  accumulated_noise_robustness: false
  step_noise_policy: false
  accumulated_noise_policy: false
  agent:
    _target_: carol.base_algorithm.pytorch_sac_pranz24.sac.SAC
    num_inputs: ???
    action_space:
      _target_: gym.env.Box
      low: ???
      high: ???
      shape: ???
    args:
      gamma: ${overrides.sac_gamma}
      tau: ${overrides.sac_tau}
      alpha: ${overrides.sac_alpha}
      policy: ${overrides.sac_policy}
      target_update_interval: ${overrides.sac_target_update_interval}
      automatic_entropy_tuning: ${overrides.sac_automatic_entropy_tuning}
      target_entropy: ${overrides.sac_target_entropy}
      hidden_size: ${overrides.sac_hidden_size}
      device: ${device}
      lr: ${overrides.sac_lr}
      truncate_scale: ${overrides.sac_truncate_scale}
  attack_agent:
    _target_: carol.base_algorithm.pytorch_sac_pranz24.sac.SAC
    num_inputs: ???
    action_space:
      _target_: gym.env.Box
      low: ???
      high: ???
      shape: ???
    args:
      gamma: ${overrides.sac_gamma}
      tau: ${overrides.sac_tau}
      alpha: ${overrides.sac_alpha}
      policy: ${overrides.sac_policy}
      target_update_interval: ${overrides.sac_target_update_interval}
      automatic_entropy_tuning: ${overrides.sac_automatic_entropy_tuning}
      target_entropy: ${overrides.sac_target_entropy}
      hidden_size: ${overrides.sac_hidden_size}
      device: ${device}
      lr: ${overrides.sac_lr}
      truncate_scale: ${overrides.sac_truncate_scale}
dynamics_model:
  _target_: carol.models.SymGaussianMLP
  device: ${device}
  num_layers: 4
  in_size: ???
  out_size: ???
  ensemble_size: 1
  hid_size: 200
  deterministic: false
  activation_fn_cfg:
    _target_: carol.modules.vrlnn.ReLU
overrides:
  env: hopper
  term_fn: hopper
  trial_length: 1000
  num_steps: 500000
  epoch_length: 1000
  num_elites: 5
  patience: 5
  model_lr: 0.001
  model_wd: 1.0e-05
  model_batch_size: 256
  validation_ratio: 0.2
  freq_train_model: 250
  effective_model_rollouts_per_step: 400
  rollout_schedule:
  - 20
  - 150
  - 1
  - 15
  num_sac_updates_per_step: 40
  sac_updates_every_steps: 1
  num_epochs_to_retain_sac_buffer: 1
  lamb: 1.0
  sac_gamma: 0.99
  sac_tau: 0.005
  sac_alpha: 0.2
  sac_policy: SymGaussian
  sac_target_update_interval: 4
  sac_automatic_entropy_tuning: false
  sac_target_entropy: -1
  sac_hidden_size: 512
  sac_lr: 0.0003
  sac_batch_size: 256
  sac_truncate_scale: 0.5
  eschedule: ref
  eschedule_start_steps: 100000
  eschedule_end_steps: 400000
  start_disturbance: 0.0
  disturbance: 0.075
  exp_scale: 10
  use_original_loss: true
  use_reward_bound: true
  use_splitter: true
  splitter: original
  partition_refined: 100
  sample_scale: 2
  model_normalization: false
  sample_original_rollout_batch: false
  partition_per_dim: 1
  keep_q_partition_per_dim: 1
  keep_q_sample_size: 1
  norm_states: true
  norm_reward: returns
  gamma: 0.99
  add_t_with_horizon: None
  clip_obs: 10.0
  clip_rew: 10.0
  show_env: false
  save_frames: false
  save_frames_path: frames/
action_optimizer:
  _target_: carol.planning.CEMOptimizer
  num_iterations: ${overrides.cem_num_iters}
  elite_ratio: ${overrides.cem_elite_ratio}
  population_size: ${overrides.cem_population_size}
  alpha: ${overrides.cem_alpha}
  lower_bound: ???
  upper_bound: ???
  return_mean_elites: true
  device: ${device}
  clipped_normal: ${overrides.cem_clipped_normal}
evaluation:
  name: provability
  concrete_num_eval_episodes: 25
  eps: 0.00392156862745098
  benchmark_name: hopper
  model_name: CAROL
  horizon_steps_list:
  - 5
  - 10
  - 15
  - 20
  - 25
